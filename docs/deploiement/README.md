# D√©ploiement

Le projet Albert est compos√© de plusieurs services √† d√©ployer :
- pyalbert
- models
- api

Pour cela vous devez d'abord disposez d'un environment r√©pondants aux exigences requises ([Requirements](#requirements)). Puis vous disposez de mani√®re de d√©ployer le projet Albert, sans Docker ([D√©ploiement sans Docker](#d√©ploiement-sans-docker)) ou avec ([D√©ploiement avec Docker](#d√©ploiement-avec-docker)).

**Tables des mati√®res**

[[_TOC_]]

## Requirements

Le projet est conc√ßu pour fonctionner sur l'environnement Linux Ubuntu 22.04 LTS. De plus, les packages sont n√©cessaires :

* jq
* python3.10
* python3.10-venv
* nvidia-driver-535
* nvidia-cuda-toolkit
* nvidia-cuda-toolkit-gcc

*Pour docker :*
* nvidia-container-toolkit
* docker-ce
* docker-ce-cli
* containerd.io
* docker-buildx-plugin
* docker-compose-plugin

Pour un d√©ploiement en production vous pouvez utiliser le script [init_vm.sh](../../utils/init_vm.sh) pour configurer l'environnement n√©cessaire au projet Albert. Copiez le script sur le serveur et ex√©cutez la commande suivante :

```bash
bash ./init_vm.sh
```

Ce script permet d'installer les packages n√©cessaires ainsi que de cr√©er un utilisation *gitlab* qui sera n√©cessaires pour le d√©ploiement de la pipeline de CI/CD. Pour ex√©cuter le script il est n√©cessaire d'exporter pr√©alablement les variables suivantes :
* `GITLAB_PASSWORD` (mot de passe de l'utilisateur *gitlab*)
* `GITLAB_SSH_PUBLIC_KEY` (clef public qui sera ajout√© √† l'utilisateur *gitlab*)

## D√©ploiement sans Docker

* Clonez le repository

	```bash
	git clone git@gitlab.com:etalab-datalab/llm/albert-backend.git albert-backend
	```

* Cr√©ez un environnement virtuel python et l'activer

	```bash
	mkdir albert && python3 -m venv albert && source albert/bin/activate
	```

	> ‚ö†Ô∏è Vous devez cr√©er cet environment avec Python 3.10.

### Pyalbert 

* Installez les packages n√©cessaires

	```bash
	pip install -r albert-backend/pyalbert/requirements.txt
	```

* Ajoutez pyalbert aux librairies de votre environment virtuel

	```bash
	ln -s albert-backend/pyalbert albert/lib/python3.10/site-packages
	```

	> ‚ö†Ô∏è Remplacez la version de Python par celle correspondante √† votre environment si celle-ci n'est pas 3.10.

### VLLM

* Installez les packages n√©cessaires

	```bash
	pip install -r albert-backend/api_vllm/requirements.txt
	```

* Configurez les mod√®les √† d√©ployer dans le fichier [vllm_routing_table.json](../../pyalbert/config/vllm_routing_table.json)

	Pour plus d'information sur comment configurer ce fichier rendez vous sur la documenntation [models.md](../models.md)

* T√©l√©chargez les mod√®les sp√©cifiez dans le fichier de configuration

	```bash
	python albert-backend/pyalbert/albert.py download_model --storage-dir STORAGE_PATH --env ENV
	```

	> üí° Remplacez STORAGE_PATH par l'emplacement o√π vous souhaitez stocker les mod√®les et ENV par la valeur que vous avez mentionn√©e dans le fichier de configuration.

 * Lancer l'API du mod√®le

	Pour chaque mod√®le vous pouvez d√©ployer une API pour int√©ragir. Commencez par d√©finir l'emplacement des mod√®les dans une variable *storage_path*.
	
	Puis s√©lectionner un mod√®le parmi ceux d√©finit le fichier de configuration :

	```bash
	routing_table=albert-backend/pyalbert/config/vllm_routing_table.json
	models=$(jq -r 'keys[]' $routing_table)

	id=$(echo "$models" | sed -n '1p')
	```

	> ‚ö†Ô∏è *1* correspond au l'index du mod√®le dans le fichier de configuration (ici c'est le premier mod√®le qui est s√©lectionn√©). Remplacez ce chiffre pour s√©lectionner un autre model

	```bash
    model=$(jq -r '.["'$id'"] | .model' $routing_table)
    port=$(jq -r '.["'$id'"] | .port' $routing_table)
    gpu_mem_use=$(jq -r '.["'$id'"] | .gpu_mem_use' $routing_table)
    tensor_parralel_size=$(jq -r '.["'$id'"] | .tensor_parralel_size' $routing_table)
	model=${storage_path}/${id}

	python albert-backend/api_vllm/app.py --host=0.0.0.0 --port=$port --model=$model --tensor-parallel-size $tensor_parralel_size --gpu-memory-utilization $gpu_mem_use
	```

### API
	
## Installation avec Docker
