# LLM

Le module LLM regroupe les différents driver pour déployer les modèles Albert présent sur le repository HuggingFace [AgentPublic](https://huggingface.co/AgentPublic).
Selon la nature du modèle, vous pouvez de déployer avec le driver VLLM (pour GPU) ou GPT4All (pour CPU). Pour plus d'information sur le déploiement des modèles référez vous la documentation dédiée : [docs/deploiement](../docs/deploiement) à la section LLM (avec ou sans Docker).